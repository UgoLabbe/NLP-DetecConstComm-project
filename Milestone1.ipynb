{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic X: Bring your own topic!\n",
    "You are encouraged to propose your own topic! Please note the following criteria:\n",
    "\n",
    "• the topic should include a text classification task at its core and there should be some\n",
    "annotated training data available for this task, otherwise milestones 1 and 2 cannot be\n",
    "completed. If you are unsure whether your topic is suitable, we are happy to advise you.\n",
    "\n",
    "• you are still required to work in teams of 4, so you should assemble a team to work on the\n",
    "project (if necessary you can also bring in external members who are not registered for the\n",
    "course)\n",
    "\n",
    "• you should contact the exercise coordinator (G ́abor Recski) about your topic proposal, we\n",
    "can discuss your ideas and recommend 1-2 instructors who can act as your mentors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\C3_anonymized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_counter</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>njudgements_constructiveness_expt</th>\n",
       "      <th>njudgements_toxicity_expt</th>\n",
       "      <th>agree_constructiveness_expt</th>\n",
       "      <th>agree_toxicity_expt</th>\n",
       "      <th>constructive</th>\n",
       "      <th>crowd_toxicity_level</th>\n",
       "      <th>...</th>\n",
       "      <th>constructive_characteristics</th>\n",
       "      <th>non_constructive_characteristics</th>\n",
       "      <th>toxicity_characteristics</th>\n",
       "      <th>crowd_comments_constructiveness_expt</th>\n",
       "      <th>crowd_comments_toxicity_expt</th>\n",
       "      <th>other_con_chars</th>\n",
       "      <th>other_noncon_chars</th>\n",
       "      <th>other_toxic_chars</th>\n",
       "      <th>constructive_binary</th>\n",
       "      <th>pp_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26023945</td>\n",
       "      <td>0</td>\n",
       "      <td>source1_26023945_62</td>\n",
       "      <td>And this Conservative strategy has produced th...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>specific_points:3\\r\\ndialogue:2</td>\n",
       "      <td>no_non_con:3\\r\\nprovocative:1</td>\n",
       "      <td>abusive:3\\r\\npersonal_attack:1\\r\\nteasing:1\\r\\...</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>And this Conservative strategy has produced th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24565777</td>\n",
       "      <td>1</td>\n",
       "      <td>source1_24565777_106</td>\n",
       "      <td>I commend Harper for holding the debates outsi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>specific_points:3\\r\\ndialogue:2</td>\n",
       "      <td>no_non_con:2\\r\\nno_respect:1</td>\n",
       "      <td>abusive:1\\r\\npersonal_attack:1\\r\\nteasing:1\\r\\...</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I commend Harper for holding the debates outsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28775443</td>\n",
       "      <td>2</td>\n",
       "      <td>source1_28775443_136</td>\n",
       "      <td>What a joke Rachel Notley is. This is what was...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>specific_points:2\\r\\ndialogue:1</td>\n",
       "      <td>no_non_con:2\\r\\nprovocative:1</td>\n",
       "      <td>personal_attack:3\\r\\ninflammatory:3\\r\\nteasing...</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What a joke Rachel Notley is . This is what wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8996700</td>\n",
       "      <td>3</td>\n",
       "      <td>source1_8996700_50</td>\n",
       "      <td>Do you need to write an essay to prove the poi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>dialogue:1\\r\\nevidence:1\\r\\nspecific_points:1</td>\n",
       "      <td>no_non_con:2\\r\\nnon_relevant:1</td>\n",
       "      <td>personal_attack:2\\r\\nteasing:2\\r\\nembarrassmen...</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Do you need to write an essay to prove the poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29405071</td>\n",
       "      <td>4</td>\n",
       "      <td>source1_29405071_126</td>\n",
       "      <td>Rob Ford was no saint. He should never have be...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>specific_points:3\\r\\nsolution:1</td>\n",
       "      <td>no_non_con:3</td>\n",
       "      <td>teasing:3\\r\\npersonal_attack:2\\r\\nabusive:1\\r\\...</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>\\r\\n\\r\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rob Ford was no saint . He should never have b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  comment_author       comment_counter  \\\n",
       "0    26023945               0   source1_26023945_62   \n",
       "1    24565777               1  source1_24565777_106   \n",
       "2    28775443               2  source1_28775443_136   \n",
       "3     8996700               3    source1_8996700_50   \n",
       "4    29405071               4  source1_29405071_126   \n",
       "\n",
       "                                        comment_text  \\\n",
       "0  And this Conservative strategy has produced th...   \n",
       "1  I commend Harper for holding the debates outsi...   \n",
       "2  What a joke Rachel Notley is. This is what was...   \n",
       "3  Do you need to write an essay to prove the poi...   \n",
       "4  Rob Ford was no saint. He should never have be...   \n",
       "\n",
       "   njudgements_constructiveness_expt  njudgements_toxicity_expt  \\\n",
       "0                                3.0                        3.0   \n",
       "1                                3.0                        3.0   \n",
       "2                                3.0                        3.0   \n",
       "3                                3.0                        3.0   \n",
       "4                                3.0                        3.0   \n",
       "\n",
       "   agree_constructiveness_expt  agree_toxicity_expt  constructive  \\\n",
       "0                         0.17                 0.50           1.0   \n",
       "1                         0.33                 0.17           1.0   \n",
       "2                         0.83                 0.00           1.0   \n",
       "3                         1.00                 0.83           1.0   \n",
       "4                         0.83                 0.33           1.0   \n",
       "\n",
       "   crowd_toxicity_level  ...                   constructive_characteristics  \\\n",
       "0                   4.0  ...                specific_points:3\\r\\ndialogue:2   \n",
       "1                   3.0  ...                specific_points:3\\r\\ndialogue:2   \n",
       "2                   3.0  ...                specific_points:2\\r\\ndialogue:1   \n",
       "3                   3.0  ...  dialogue:1\\r\\nevidence:1\\r\\nspecific_points:1   \n",
       "4                   3.0  ...                specific_points:3\\r\\nsolution:1   \n",
       "\n",
       "  non_constructive_characteristics  \\\n",
       "0    no_non_con:3\\r\\nprovocative:1   \n",
       "1     no_non_con:2\\r\\nno_respect:1   \n",
       "2    no_non_con:2\\r\\nprovocative:1   \n",
       "3   no_non_con:2\\r\\nnon_relevant:1   \n",
       "4                     no_non_con:3   \n",
       "\n",
       "                            toxicity_characteristics  \\\n",
       "0  abusive:3\\r\\npersonal_attack:1\\r\\nteasing:1\\r\\...   \n",
       "1  abusive:1\\r\\npersonal_attack:1\\r\\nteasing:1\\r\\...   \n",
       "2  personal_attack:3\\r\\ninflammatory:3\\r\\nteasing...   \n",
       "3  personal_attack:2\\r\\nteasing:2\\r\\nembarrassmen...   \n",
       "4  teasing:3\\r\\npersonal_attack:2\\r\\nabusive:1\\r\\...   \n",
       "\n",
       "  crowd_comments_constructiveness_expt crowd_comments_toxicity_expt  \\\n",
       "0                             \\r\\n\\r\\n                     \\r\\n\\r\\n   \n",
       "1                             \\r\\n\\r\\n                     \\r\\n\\r\\n   \n",
       "2                             \\r\\n\\r\\n                     \\r\\n\\r\\n   \n",
       "3                             \\r\\n\\r\\n                     \\r\\n\\r\\n   \n",
       "4                             \\r\\n\\r\\n                     \\r\\n\\r\\n   \n",
       "\n",
       "  other_con_chars other_noncon_chars other_toxic_chars constructive_binary  \\\n",
       "0        \\r\\n\\r\\n           \\r\\n\\r\\n          \\r\\n\\r\\n                 1.0   \n",
       "1        \\r\\n\\r\\n           \\r\\n\\r\\n          \\r\\n\\r\\n                 1.0   \n",
       "2        \\r\\n\\r\\n           \\r\\n\\r\\n          \\r\\n\\r\\n                 1.0   \n",
       "3        \\r\\n\\r\\n           \\r\\n\\r\\n          \\r\\n\\r\\n                 1.0   \n",
       "4        \\r\\n\\r\\n           \\r\\n\\r\\n          \\r\\n\\r\\n                 1.0   \n",
       "\n",
       "                                     pp_comment_text  \n",
       "0  And this Conservative strategy has produced th...  \n",
       "1  I commend Harper for holding the debates outsi...  \n",
       "2  What a joke Rachel Notley is . This is what wa...  \n",
       "3  Do you need to write an essay to prove the poi...  \n",
       "4  Rob Ford was no saint . He should never have b...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between column 'comment_text' and 'pp_comment_text':\n",
    "\n",
    "Seems like it's a \"pre-cleaned\" text column:\n",
    "- remove hyphen (')\n",
    "- Added whitespace before-after points, coma, apostrophe \n",
    "- kept - in words such as 'left-wing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment text:\n",
      " And this Conservative strategy has produced the angry and desperate wing-nuts like the fellow who called reporters 'lying pieces of Sh*t' this week. The fortunate thing is that reporters were able to report it and broadcast it - which may shake up a few folks who recognize a bit of themselves somewhere in there and do some reflecting. I live in hope. \n",
      "\n",
      "pp Comment text:\n",
      " And this Conservative strategy has produced the angry and desperate wing-nuts like the fellow who called reporters lying pieces of Sh*t this week . The fortunate thing is that reporters were able to report it and broadcast it - which may shake up a few folks who recognize a bit of themselves somewhere in there and do some reflecting . I live in hope . \n",
      "-----------------------------\n",
      "Comment text:\n",
      " I commend Harper for holding the debates outside of a left-wing forum as this will help prevent the left from manipulating the debates to try to make Harper look bad. Indeed, we’ll finally have some fair debates. Trudeau is a coward and the only one who’s opposing this as he’s terrified about losing left-wing protection during the debates if the debates are held elsewhere. If Trudeau doesn’t have Chretien or Martin speaking for him or isn't currently in training to learn how to handle himself in a debate, he has May attending the debates to hold his little hand. If Trudeau can’t speak for himself or handle debates, how does he expect to run a country? \n",
      "\n",
      "pp Comment text:\n",
      " I commend Harper for holding the debates outside of a left-wing forum as this will help prevent the left from manipulating the debates to try to make Harper look bad . Indeed , we ’ ll finally have some fair debates . Trudeau is a coward and the only one who ’ s opposing this as he ’ s terrified about losing left-wing protection during the debates if the debates are held elsewhere . If Trudeau doesn ’ t have Chretien or Martin speaking for him or isnt currently in training to learn how to handle himself in a debate , he has May attending the debates to hold his little hand . If Trudeau can ’ t speak for himself or handle debates , how does he expect to run a country ? \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    print(\"Comment text:\\n\",df[\"comment_text\"][i],\"\\n\\npp Comment text:\\n\",df[\"pp_comment_text\"][i],\"\\n-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset with untreated comment annotation about constructiveness (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructive_binary\n",
      "1.0    6516\n",
      "0.0    5484\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_anno = df[['comment_text','constructive_binary']]\n",
    "print(df_anno['constructive_binary'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the constructive and non-constructive comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Constructive Comments:\n",
      "10541                                                                                                                                                                                                                                                                                                                                                                                                                                  The world & the west will be better when the Globalists are all voted out of office. They show very little concern for their own citizens and instead try to one-up each other by impressing the dictators or climate change zealots at the UN.\n",
      "3140     Actions speak louder than words of condolence. Withdrawing was the wrong thing to do a week ago and its the wrong thing to do now. Giving in to the ruthless intimidation tactics of this cancer on humanity is exactly what ISIS is trying to achieve. It's time to stand with the Free-world and in particular France in maintaining the offensive. The coalition airstrikes are just starting to have the desired effect, such as the case in Sinjar Iraq where the Peshmerga Kurds now have a strategic advantage thanks to the air support provided in part by Canadian F-18s. Lets not give ISIS a victory by standing with of friends both figuratively and literally.\n",
      "1445                                                                                                                                            How daft does Wente think we are?! How can you possibly compare hordes of migrants and refugees trekking across Europe and Germany taking one million of them after little or no screening to Canada taking 25,000 screened Syrian refugees? Also, why does Wente not mention that of the migrants picked up by the Cologne police, the majority of them were North African Arabs from Morocco and Algeria, not Syrian refugees? I believe that they have one Syrian. Some of the guys picked up were in Germany completely illegally.\n",
      "Name: comment_text, dtype: object\n",
      "\n",
      "Random Non-Constructive Comments:\n",
      "8735                                                                                                                                                                                                                                                                                                                                                                                              There's been many a stupid globe editorial, this is the top of the list.\n",
      "590     Why is the Globe & Mail so worried? Starting to look like Hillary is gunna lose so you are trying to affect American voters? Really G & M? It's not like we don't have enough of our own problems here in Canada that you feel you have to insert yourself in the American election. You are starting to sound as pathetic and desperate as CNN. That fact that you think Hillary is mildly flawed is laughable. She is far more dangerous than Trump can ever be.\n",
      "565                                                                                                                                                                                                                                                                                                                                                                                                  The censorship here is not unlike that of Iran or modern day Turkey..\n",
      "Name: comment_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Randomly sample 3 constructive comments\n",
    "random_constructive = df_anno[df_anno['constructive_binary'] == 1].sample(n=3, random_state=42)\n",
    "\n",
    "# Randomly sample 3 non-constructive comments\n",
    "random_non_constructive = df_anno[df_anno['constructive_binary'] == 0].sample(n=3, random_state=42)\n",
    "\n",
    "# Display the results\n",
    "print(\"Random Constructive Comments:\")\n",
    "print(random_constructive['comment_text'])\n",
    "print(\"\\nRandom Non-Constructive Comments:\")\n",
    "print(random_non_constructive['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some possible issues that we saw:\n",
    "- use of slang like \"gonna, gunna\" for \"going to\"\n",
    "- abreviations\n",
    "- spelling mistakes\n",
    "- telling if a comment is constructive or not can be highly subjective. That's most likely why a non-binary annotation column exist, most fitted for a regression task\n",
    "\n",
    "but overall the texts seems cleans in general\n",
    "\n",
    "Now let's build a function to see which words are the most used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies and download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import stanza\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_most_used_words(text_list, top_n=10, language='english'):\n",
    "    #Summarizes the most used words in a list of text, excluding stopwords.\n",
    "\n",
    "    # Load the stopwords for the given language\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    \n",
    "    # Combine all texts into one large string\n",
    "    all_text = ' '.join(text_list)\n",
    "    \n",
    "    # Convert to lowercase and remove punctuation using regex\n",
    "    all_text_cleaned = re.sub(r'[^\\w\\s]', '', all_text.lower())\n",
    "    \n",
    "    # Split into words\n",
    "    words = word_tokenize(all_text_cleaned, language='english')\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Count word frequencies and get the most common\n",
    "    word_counts = Counter(filtered_words)\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    return most_common_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 2817),\n",
       " ('would', 2666),\n",
       " ('canada', 2528),\n",
       " ('harper', 2444),\n",
       " ('one', 2190),\n",
       " ('like', 2128),\n",
       " ('us', 1833),\n",
       " ('dont', 1691),\n",
       " ('government', 1654),\n",
       " ('get', 1566),\n",
       " ('time', 1506),\n",
       " ('many', 1410),\n",
       " ('think', 1268),\n",
       " ('years', 1266),\n",
       " ('even', 1254),\n",
       " ('canadian', 1238),\n",
       " ('party', 1192),\n",
       " ('well', 1176),\n",
       " ('canadians', 1161),\n",
       " ('good', 1156),\n",
       " ('right', 1140),\n",
       " ('much', 1113),\n",
       " ('see', 1083),\n",
       " ('world', 1081),\n",
       " ('trudeau', 1060)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_most_used_words(df_anno['comment_text'], top_n=25, language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for Pre-processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
