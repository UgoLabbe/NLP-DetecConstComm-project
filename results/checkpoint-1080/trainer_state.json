{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1080,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009259259259259259,
      "grad_norm": 4.439280033111572,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.7277,
      "step": 10
    },
    {
      "epoch": 0.018518518518518517,
      "grad_norm": 8.950873374938965,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.7228,
      "step": 20
    },
    {
      "epoch": 0.027777777777777776,
      "grad_norm": 3.9286797046661377,
      "learning_rate": 3e-06,
      "loss": 0.6769,
      "step": 30
    },
    {
      "epoch": 0.037037037037037035,
      "grad_norm": 8.793628692626953,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6457,
      "step": 40
    },
    {
      "epoch": 0.046296296296296294,
      "grad_norm": 5.118696689605713,
      "learning_rate": 5e-06,
      "loss": 0.5729,
      "step": 50
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 9.963205337524414,
      "learning_rate": 6e-06,
      "loss": 0.521,
      "step": 60
    },
    {
      "epoch": 0.06481481481481481,
      "grad_norm": 7.262749671936035,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.5126,
      "step": 70
    },
    {
      "epoch": 0.07407407407407407,
      "grad_norm": 18.62522315979004,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.4464,
      "step": 80
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 7.297521591186523,
      "learning_rate": 9e-06,
      "loss": 0.4239,
      "step": 90
    },
    {
      "epoch": 0.09259259259259259,
      "grad_norm": 9.70535659790039,
      "learning_rate": 1e-05,
      "loss": 0.3768,
      "step": 100
    },
    {
      "epoch": 0.10185185185185185,
      "grad_norm": 8.339592933654785,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.3766,
      "step": 110
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 8.104011535644531,
      "learning_rate": 1.2e-05,
      "loss": 0.3453,
      "step": 120
    },
    {
      "epoch": 0.12037037037037036,
      "grad_norm": 3.6527509689331055,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.3225,
      "step": 130
    },
    {
      "epoch": 0.12962962962962962,
      "grad_norm": 3.9925076961517334,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.2968,
      "step": 140
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 14.856379508972168,
      "learning_rate": 1.5e-05,
      "loss": 0.2846,
      "step": 150
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 26.045665740966797,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.2059,
      "step": 160
    },
    {
      "epoch": 0.1574074074074074,
      "grad_norm": 7.1177496910095215,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.182,
      "step": 170
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 13.809427261352539,
      "learning_rate": 1.8e-05,
      "loss": 0.3152,
      "step": 180
    },
    {
      "epoch": 0.17592592592592593,
      "grad_norm": 13.220126152038574,
      "learning_rate": 1.9e-05,
      "loss": 0.1773,
      "step": 190
    },
    {
      "epoch": 0.18518518518518517,
      "grad_norm": 1.443801760673523,
      "learning_rate": 2e-05,
      "loss": 0.279,
      "step": 200
    },
    {
      "epoch": 0.19444444444444445,
      "grad_norm": 34.226741790771484,
      "learning_rate": 2.1e-05,
      "loss": 0.1139,
      "step": 210
    },
    {
      "epoch": 0.2037037037037037,
      "grad_norm": 11.968201637268066,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.3312,
      "step": 220
    },
    {
      "epoch": 0.21296296296296297,
      "grad_norm": 0.835019588470459,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.1139,
      "step": 230
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.294230580329895,
      "learning_rate": 2.4e-05,
      "loss": 0.4039,
      "step": 240
    },
    {
      "epoch": 0.23148148148148148,
      "grad_norm": 2.2741663455963135,
      "learning_rate": 2.5e-05,
      "loss": 0.0633,
      "step": 250
    },
    {
      "epoch": 0.24074074074074073,
      "grad_norm": 0.23479712009429932,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.2107,
      "step": 260
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5181750059127808,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.3893,
      "step": 270
    },
    {
      "epoch": 0.25925925925925924,
      "grad_norm": 13.907724380493164,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.315,
      "step": 280
    },
    {
      "epoch": 0.26851851851851855,
      "grad_norm": 3.4592015743255615,
      "learning_rate": 2.9e-05,
      "loss": 0.1825,
      "step": 290
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 6.731849193572998,
      "learning_rate": 3e-05,
      "loss": 0.3639,
      "step": 300
    },
    {
      "epoch": 0.28703703703703703,
      "grad_norm": 0.5060593485832214,
      "learning_rate": 3.1e-05,
      "loss": 0.2353,
      "step": 310
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 16.037940979003906,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.362,
      "step": 320
    },
    {
      "epoch": 0.3055555555555556,
      "grad_norm": 21.230981826782227,
      "learning_rate": 3.3e-05,
      "loss": 0.3276,
      "step": 330
    },
    {
      "epoch": 0.3148148148148148,
      "grad_norm": 1.3190861940383911,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.5283,
      "step": 340
    },
    {
      "epoch": 0.32407407407407407,
      "grad_norm": 44.62590789794922,
      "learning_rate": 3.5e-05,
      "loss": 0.2121,
      "step": 350
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.5778866410255432,
      "learning_rate": 3.6e-05,
      "loss": 0.2728,
      "step": 360
    },
    {
      "epoch": 0.3425925925925926,
      "grad_norm": 25.428504943847656,
      "learning_rate": 3.7e-05,
      "loss": 0.451,
      "step": 370
    },
    {
      "epoch": 0.35185185185185186,
      "grad_norm": 5.642666816711426,
      "learning_rate": 3.8e-05,
      "loss": 0.3977,
      "step": 380
    },
    {
      "epoch": 0.3611111111111111,
      "grad_norm": 0.845439076423645,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4699,
      "step": 390
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 5.4814677238464355,
      "learning_rate": 4e-05,
      "loss": 0.4322,
      "step": 400
    },
    {
      "epoch": 0.37962962962962965,
      "grad_norm": 4.990299224853516,
      "learning_rate": 4.1e-05,
      "loss": 0.196,
      "step": 410
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 0.4359472990036011,
      "learning_rate": 4.2e-05,
      "loss": 0.1486,
      "step": 420
    },
    {
      "epoch": 0.39814814814814814,
      "grad_norm": 12.695402145385742,
      "learning_rate": 4.3e-05,
      "loss": 0.368,
      "step": 430
    },
    {
      "epoch": 0.4074074074074074,
      "grad_norm": 17.017972946166992,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4757,
      "step": 440
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.9060226678848267,
      "learning_rate": 4.5e-05,
      "loss": 0.2318,
      "step": 450
    },
    {
      "epoch": 0.42592592592592593,
      "grad_norm": 32.93205261230469,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.3045,
      "step": 460
    },
    {
      "epoch": 0.4351851851851852,
      "grad_norm": 0.1469859927892685,
      "learning_rate": 4.7e-05,
      "loss": 0.089,
      "step": 470
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.09950914233922958,
      "learning_rate": 4.8e-05,
      "loss": 0.2796,
      "step": 480
    },
    {
      "epoch": 0.4537037037037037,
      "grad_norm": 0.2805453836917877,
      "learning_rate": 4.9e-05,
      "loss": 0.1928,
      "step": 490
    },
    {
      "epoch": 0.46296296296296297,
      "grad_norm": 16.2227840423584,
      "learning_rate": 5e-05,
      "loss": 0.4741,
      "step": 500
    },
    {
      "epoch": 0.4722222222222222,
      "grad_norm": 0.7126441597938538,
      "learning_rate": 4.981751824817518e-05,
      "loss": 0.3374,
      "step": 510
    },
    {
      "epoch": 0.48148148148148145,
      "grad_norm": 0.6404715776443481,
      "learning_rate": 4.963503649635037e-05,
      "loss": 0.2822,
      "step": 520
    },
    {
      "epoch": 0.49074074074074076,
      "grad_norm": 1.6676695346832275,
      "learning_rate": 4.945255474452555e-05,
      "loss": 0.1263,
      "step": 530
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.41133975982666,
      "learning_rate": 4.927007299270073e-05,
      "loss": 0.1778,
      "step": 540
    },
    {
      "epoch": 0.5092592592592593,
      "grad_norm": 0.1842283457517624,
      "learning_rate": 4.908759124087591e-05,
      "loss": 0.26,
      "step": 550
    },
    {
      "epoch": 0.5185185185185185,
      "grad_norm": 0.1986425369977951,
      "learning_rate": 4.89051094890511e-05,
      "loss": 0.2939,
      "step": 560
    },
    {
      "epoch": 0.5277777777777778,
      "grad_norm": 0.8916694521903992,
      "learning_rate": 4.872262773722628e-05,
      "loss": 0.2802,
      "step": 570
    },
    {
      "epoch": 0.5370370370370371,
      "grad_norm": 23.042749404907227,
      "learning_rate": 4.854014598540147e-05,
      "loss": 0.3836,
      "step": 580
    },
    {
      "epoch": 0.5462962962962963,
      "grad_norm": 12.652247428894043,
      "learning_rate": 4.835766423357664e-05,
      "loss": 0.5146,
      "step": 590
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.8540802001953125,
      "learning_rate": 4.817518248175183e-05,
      "loss": 0.2038,
      "step": 600
    },
    {
      "epoch": 0.5648148148148148,
      "grad_norm": 5.484358787536621,
      "learning_rate": 4.799270072992701e-05,
      "loss": 0.3813,
      "step": 610
    },
    {
      "epoch": 0.5740740740740741,
      "grad_norm": 0.2810669243335724,
      "learning_rate": 4.7810218978102196e-05,
      "loss": 0.1666,
      "step": 620
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 0.2794305682182312,
      "learning_rate": 4.762773722627738e-05,
      "loss": 0.178,
      "step": 630
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 8.35552978515625,
      "learning_rate": 4.744525547445256e-05,
      "loss": 0.3932,
      "step": 640
    },
    {
      "epoch": 0.6018518518518519,
      "grad_norm": 1.274025321006775,
      "learning_rate": 4.726277372262774e-05,
      "loss": 0.2676,
      "step": 650
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 0.08667869865894318,
      "learning_rate": 4.708029197080292e-05,
      "loss": 0.0823,
      "step": 660
    },
    {
      "epoch": 0.6203703703703703,
      "grad_norm": 33.97312927246094,
      "learning_rate": 4.6897810218978106e-05,
      "loss": 0.2274,
      "step": 670
    },
    {
      "epoch": 0.6296296296296297,
      "grad_norm": 1.1098508834838867,
      "learning_rate": 4.6715328467153287e-05,
      "loss": 0.4919,
      "step": 680
    },
    {
      "epoch": 0.6388888888888888,
      "grad_norm": 4.724392414093018,
      "learning_rate": 4.6532846715328474e-05,
      "loss": 0.454,
      "step": 690
    },
    {
      "epoch": 0.6481481481481481,
      "grad_norm": 4.841236591339111,
      "learning_rate": 4.635036496350365e-05,
      "loss": 0.159,
      "step": 700
    },
    {
      "epoch": 0.6574074074074074,
      "grad_norm": 0.6893365383148193,
      "learning_rate": 4.6167883211678835e-05,
      "loss": 0.3592,
      "step": 710
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 7.267207622528076,
      "learning_rate": 4.5985401459854016e-05,
      "loss": 0.3921,
      "step": 720
    },
    {
      "epoch": 0.6759259259259259,
      "grad_norm": 0.6260819435119629,
      "learning_rate": 4.58029197080292e-05,
      "loss": 0.2319,
      "step": 730
    },
    {
      "epoch": 0.6851851851851852,
      "grad_norm": 6.07451057434082,
      "learning_rate": 4.5620437956204383e-05,
      "loss": 0.2954,
      "step": 740
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.40631103515625,
      "learning_rate": 4.5437956204379564e-05,
      "loss": 0.2651,
      "step": 750
    },
    {
      "epoch": 0.7037037037037037,
      "grad_norm": 0.30304569005966187,
      "learning_rate": 4.5255474452554745e-05,
      "loss": 0.264,
      "step": 760
    },
    {
      "epoch": 0.7129629629629629,
      "grad_norm": 7.231122016906738,
      "learning_rate": 4.5072992700729925e-05,
      "loss": 0.1915,
      "step": 770
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.2893381118774414,
      "learning_rate": 4.489051094890511e-05,
      "loss": 0.1831,
      "step": 780
    },
    {
      "epoch": 0.7314814814814815,
      "grad_norm": 10.34627914428711,
      "learning_rate": 4.470802919708029e-05,
      "loss": 0.2437,
      "step": 790
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 4.937499046325684,
      "learning_rate": 4.452554744525548e-05,
      "loss": 0.3024,
      "step": 800
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.9688191413879395,
      "learning_rate": 4.434306569343066e-05,
      "loss": 0.2544,
      "step": 810
    },
    {
      "epoch": 0.7592592592592593,
      "grad_norm": 0.4539767801761627,
      "learning_rate": 4.416058394160584e-05,
      "loss": 0.3285,
      "step": 820
    },
    {
      "epoch": 0.7685185185185185,
      "grad_norm": 0.8286867737770081,
      "learning_rate": 4.397810218978102e-05,
      "loss": 0.2803,
      "step": 830
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 7.3748087882995605,
      "learning_rate": 4.379562043795621e-05,
      "loss": 0.3551,
      "step": 840
    },
    {
      "epoch": 0.7870370370370371,
      "grad_norm": 2.4606430530548096,
      "learning_rate": 4.361313868613139e-05,
      "loss": 0.2191,
      "step": 850
    },
    {
      "epoch": 0.7962962962962963,
      "grad_norm": 4.6889848709106445,
      "learning_rate": 4.343065693430657e-05,
      "loss": 0.1092,
      "step": 860
    },
    {
      "epoch": 0.8055555555555556,
      "grad_norm": 0.4675692915916443,
      "learning_rate": 4.324817518248175e-05,
      "loss": 0.214,
      "step": 870
    },
    {
      "epoch": 0.8148148148148148,
      "grad_norm": 16.90774154663086,
      "learning_rate": 4.306569343065693e-05,
      "loss": 0.255,
      "step": 880
    },
    {
      "epoch": 0.8240740740740741,
      "grad_norm": 0.7255963087081909,
      "learning_rate": 4.288321167883212e-05,
      "loss": 0.2293,
      "step": 890
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.1807517558336258,
      "learning_rate": 4.27007299270073e-05,
      "loss": 0.2189,
      "step": 900
    },
    {
      "epoch": 0.8425925925925926,
      "grad_norm": 0.17579303681850433,
      "learning_rate": 4.251824817518249e-05,
      "loss": 0.2353,
      "step": 910
    },
    {
      "epoch": 0.8518518518518519,
      "grad_norm": 0.48084840178489685,
      "learning_rate": 4.233576642335767e-05,
      "loss": 0.2998,
      "step": 920
    },
    {
      "epoch": 0.8611111111111112,
      "grad_norm": 4.438077449798584,
      "learning_rate": 4.215328467153285e-05,
      "loss": 0.1686,
      "step": 930
    },
    {
      "epoch": 0.8703703703703703,
      "grad_norm": 0.4420095384120941,
      "learning_rate": 4.197080291970803e-05,
      "loss": 0.1852,
      "step": 940
    },
    {
      "epoch": 0.8796296296296297,
      "grad_norm": 48.188045501708984,
      "learning_rate": 4.1788321167883216e-05,
      "loss": 0.2445,
      "step": 950
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.7552152872085571,
      "learning_rate": 4.16058394160584e-05,
      "loss": 0.244,
      "step": 960
    },
    {
      "epoch": 0.8981481481481481,
      "grad_norm": 3.6436641216278076,
      "learning_rate": 4.1423357664233584e-05,
      "loss": 0.268,
      "step": 970
    },
    {
      "epoch": 0.9074074074074074,
      "grad_norm": 0.30063924193382263,
      "learning_rate": 4.124087591240876e-05,
      "loss": 0.2608,
      "step": 980
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 0.3663531541824341,
      "learning_rate": 4.1058394160583945e-05,
      "loss": 0.2863,
      "step": 990
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 7.820816993713379,
      "learning_rate": 4.0875912408759126e-05,
      "loss": 0.2105,
      "step": 1000
    },
    {
      "epoch": 0.9351851851851852,
      "grad_norm": 12.176673889160156,
      "learning_rate": 4.0693430656934306e-05,
      "loss": 0.2019,
      "step": 1010
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 10.591497421264648,
      "learning_rate": 4.0510948905109494e-05,
      "loss": 0.3357,
      "step": 1020
    },
    {
      "epoch": 0.9537037037037037,
      "grad_norm": 0.48256218433380127,
      "learning_rate": 4.0328467153284674e-05,
      "loss": 0.2952,
      "step": 1030
    },
    {
      "epoch": 0.9629629629629629,
      "grad_norm": 1.1705836057662964,
      "learning_rate": 4.0145985401459855e-05,
      "loss": 0.3076,
      "step": 1040
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 10.397361755371094,
      "learning_rate": 3.9963503649635035e-05,
      "loss": 0.1307,
      "step": 1050
    },
    {
      "epoch": 0.9814814814814815,
      "grad_norm": 4.195181846618652,
      "learning_rate": 3.978102189781022e-05,
      "loss": 0.2612,
      "step": 1060
    },
    {
      "epoch": 0.9907407407407407,
      "grad_norm": 0.3822416067123413,
      "learning_rate": 3.95985401459854e-05,
      "loss": 0.4037,
      "step": 1070
    },
    {
      "epoch": 1.0,
      "grad_norm": 76.28103637695312,
      "learning_rate": 3.941605839416059e-05,
      "loss": 0.1608,
      "step": 1080
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.23229672014713287,
      "eval_runtime": 7.0351,
      "eval_samples_per_second": 136.459,
      "eval_steps_per_second": 8.529,
      "step": 1080
    }
  ],
  "logging_steps": 10,
  "max_steps": 3240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 568254101813760.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
